# Matrices

## Matrix Operations

> **Definition:** Matrix  
> If $A$ is an $m\times n$ matrix, then:  
> $A = \begin{bmatrix}a_11 && ... && a_1n \\ ... \\ a_m1 && ... && a_mn\end{bmatrix}$  
> Where $a_ij$ is the entry on the $i^{th}$ row and
> $j^{th}$ column.  
> They are normally denoted as $\textbf{A}$, or simply $A$.

> **Definition:** Vector  
> Vectors can be thought of as a $\begin{aligned}\end{aligned}1 \times n$ or $m \times 1$ matrix,
> a row vector and column vector, respectively.  
> They are normally denoted as $\vec a$ or $\textbf{a}$

### Equality

> **Definition:** Two $m\times n$ matrices $\textbf{A}$ and $\textbf{B}$
> are equal if all of their components (in corresponding locations)
> are equal.

### Scalar Multiplication

Given:

$$b\textbf{A}$$

The resulting matrix is given by:

$$ba_{ij}$$

For every $i,j$.

$$
\textbf{A} = 
\left[
\begin{array}{cc}
1 & 2 \\ 3 & 4
\end{array}
\right]
$$

$$
b\textbf{A} = 
\left[
\begin{array}{cc}
b1 & b2 \\ b3 & b4
\end{array}
\right]
$$

### Addition/Subtraction

Given:

$$\textbf{A} \pm \textbf{B}$$

The final matrix is given by:

$$a_{ij} \pm b_ij$$

Where $a_{ij}$ is each element in $\textbf{A}$, and the same for $b_{ij}$

### Transpose

Given $\textbf{B}$ is the transpose of $\textbf{A}$:

$$b_{ij} = a_{ji}$$

Which swaps the columns with the rows.

This is normally denoted as $\textbf{A}^T$.

$$
\left[
\begin{array}{cc}
1 & 2 \\ 3 & 4 \\ 5 & 6
\end{array}
\right]^T = 
\left[
\begin{array}{ccc}
1 & 3 & 5 \\ 2 & 4 & 6
\end{array}
\right]
$$

> **Definition:** $\textbf{A}$ is **symmetric** if $\textbf{A} = \textbf{A}^T$

### Matrix Multiplication

If $\textbf{A}$ is a $m \times n$ matrix, and $\textbf{B}$ must be a $n \times r$ matrix. Note that the second dimension of the first matrix and the first of the second are the same.

$$\textbf{C} = \textbf{AB}$$

$$c_{ij} = a_{i1}b{1j} + a_{i2}b_{2j} ... a_{in}b_{nj}$$
$$c_{ij} = \sum\limits_{k=1}^n a_{ik}b_{kj}$$

~~Example 1

$$
\textbf{A} = 
\left[
\begin{array}{cc}
3 & -2 \\ 2 & 4 \\ 1 & -3
\end{array}
\right]
$$
$$
\textbf{B} = 
\left[
\begin{array}{cc}
-2 & 1 \\ 4 & 1
\end{array}
\right]
$$

These can be multiplied, as they have the correct corresponding dimension. So, we can multiply, going row-by-row in the first matrix and column-by-column in the second:

$$
\textbf{AB} = 
\left[
\begin{array}{cc}
3(-2)+(-2)4 & 3(1) + (-2)1 \\ 
2(-2) + (4)4 & 2(1) + 4(1) \\ 
1(-2) + -3(4) & 1(1) + (-3)1
\end{array}
\right]
$$
$$
= 
\left[
\begin{array}{cc}
-14 & 1 \\ 12 & 6 \\ -14 & -2
\end{array}
\right]
$$

~~

Note that often $\textbf{AB} \ne \textbf{BA}$. This is different from normal algebraic rules.

The important feature of matrix multiplication is that it can represent linear systems:

$$\textbf{A}\vec x = \vec b$$

Using this notation represents the corresponding system of equations:

$$
\left[
\begin{array}{ccc}
a_11 & ... & a_1n \\
 &... 
\\ a_m1 & ... & a_mn
\end{array}
\right]
\left[
\begin{array}{c}
x_1 \\ ... \\ x_n
\end{array}
\right]
=
\left[
\begin{array}{c}
b_1 \\ ... \\ b_m
\end{array}
\right]
$$

Is the same as (doing the multiplication):

$$
\begin{cases}
a_11x_1 + ... + a_1nx_n = b_1 \\
... \\
a_m1x_1 + ... + a_mnx_n = b_m \\
\end{cases}
$$

### Power Notation

$$\textbf{A}^2 = \textbf{AA}$$
$$\textbf{A}^k = \textbf{AA}...\textbf{A},\ k\ times.$$

Note that powers can only be used on $n \times n$ matrixes, as otherwise the matrix multiplication would not be possible.

### Identity

> Definition: Identity matrix  
> The identity matrix is defined as the matrix which results in no change after multiplication.
> $\textbf{AI} = \textbf{IA} = \textbf{A}$
> Where $\textbf{I}$ is the identity matrix.
> It has all zero elements except a the diagonal down the center.

$$
\textbf{I}_{2\times 2} = 
\left[
\begin{array}{cc}
1 & 0 \\ 0 & 1
\end{array}
\right]
$$
$$
\textbf{I}_{3\times 3} = 
\left[
\begin{array}{ccc}
1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1
\end{array}
\right]
$$

### Zero Matrix

$$
0 = \textbf{0} = 
\left[
\begin{array}{ccc}
0 & ... & 0 \\ &... \\ 0 & ... & 0
\end{array}
\right]
$$

### Inverse

> Definition: Inverse
> An $n \times n$ matrix $\textbf{A}$ is **non-singular** or **invertible** if there is a matrix $\textbf{B}$ where
> $\textbf{AB} = \textbf{BA} = \textbf{I}$
> ($\textbf{B}$ is the multiplicative inverse of $\textbf{A}$)
> denoted $\textbf{A}^{-1}$

Note that the inverse is unique.

~~Proof

Suppose $\textbf{B}$ and $\textbf{C}$ are inverses of $\textbf{A}$. We need to show that $\textbf{B} = \textbf{C}$.

$$\textbf{AB} = \textbf{I}$$
$$\textbf{CAB} = \textbf{CI}$$
$$\textbf{IB} = \textbf{CI}$$
$$\textbf{B}=\textbf{C}$$

~~

> Definition: Singular
> $\textbf{A}$ is **singular** if it does not have an inverse.

~~Example 2

$$
\left[
\begin{array}{cc}
2 & -1 \\
3 & 1
\end{array}
\right]
$$
$$
\left[
\begin{array}{cc}
\frac{1}{5} & \frac{1}{5} \\
-\frac{3}{5} & \frac{2}{5}
\end{array}
\right]
$$

Verify that these are inverses:

$$
\left[
\begin{array}{cc}
2 & -1 \\
3 & 1
\end{array}
\right]
\left[
\begin{array}{cc}
\frac{1}{5} & \frac{1}{5} \\
-\frac{3}{5} & \frac{2}{5}
\end{array}
\right]
=
\left[
\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right]
$$

~~

The main use for inverses is to manipulate equations with matrices:

Given a system $\textbf{A}\vec x = \vec b$, If we can find the inverse of $\textbf{A}$, we can solve.

$$\textbf{A}^{-1}\textbf{A}\vec x = \textbf{A}^{-1}b$$
$$\vec x = \textbf{A}^{-1}\vec b$$

Which gives a constant solution for each $x_n$

To find the inverse of a matrix, set up the augmented matrix:

$$
\left[
\begin{array}{c|c}
\textbf{A} & \textbf{I}
\end{array}
\right]
$$

Then transform to reduced row-echelon form to get:
$$
\left[
\begin{array}{c|c}
\textbf{I} & \textbf{A}^{-1}
\end{array}
\right]
$$

~~Example 3
$$
\textbf{A} =
\left[
\begin{array}{cc}
1 & 3 \\
2 & 4
\end{array}
\right]
$$

Find $\textbf{A}^{-1}$ and solve:

$$
\begin{cases}
x + 3y = 1 \\
2x + 4y = 2
\end{cases}
$$

So, we first set up the augmented matrix:
$$
\left[
\begin{array}{c|c}
\textbf{A} & \textbf{I}
\end{array}
\right]
$$
$$
\left[
\begin{array}{cc|cc}
1 & 3 & 1 & 0 \\
2 & 4 & 0 & 1
\end{array}
\right]
$$
$$
\left[
\begin{array}{cc|cc}
1 & 3 & 1 & 0 \\
0 & -2 & -2 & 1
\end{array}
\right]
$$
$$
\left[
\begin{array}{cc|cc}
1 & 3 & 1 & 0 \\
0 & 1 & 1 & -\frac{1}{2}
\end{array}
\right]
$$
$$
\left[
\begin{array}{cc|cc}
1 & 0 & -2 & \frac{3}{2} \\
0 & 1 & 1 & -\frac{1}{2}
\end{array}
\right]
$$
$$
\left[
\begin{array}{c|c}
\textbf{I} & \textbf{A}^{-1}
\end{array}
\right]
$$

So we have:

$$
\textbf{A}^{-1} =
\left[
\begin{array}{cc}
-2 & \frac{3}{2} \\
1 & -\frac{1}{2}
\end{array}
\right]
$$

So we now try to solve the system:

$$\textbf{A}\vec x = \vec b$$
$$\textbf{A}\textbf{A}^{-1}\vec x = \textbf{A}^{-1}\vec b$$
$$\vec x = \textbf{A}^{-1}\vec b$$
$$
\left[
\begin{array}{c}
x \\ y
\end{array}
\right]
= 
\left[
\begin{array}{cc}
-2 & \frac{3}{2} \\
1 & -\frac{1}{2}
\end{array}
\right]
\left[
\begin{array}{c}
1 \\ 2
\end{array}
\right]
$$
$$
\left[
\begin{array}{c}
x \\ y
\end{array}
\right]
= 
\left[
\begin{array}{c}
1 \\ 0
\end{array}
\right]
$$

So the solution is $(1,0)$.

~~

### Determinant

## Algebraic Rules for Matrices

Again, remember that the order of matrix operation matters:

$$\textbf{AB} \ne \textbf{BA}$$

### Rules for multiplication:

Note: bold face is not used for (my) convience.

1. $$A + B = B + A$$
2. $$(A+B) + C = A + (B + C)$$
3. $$(AB)C = A(BC)$$
4. $$A(B+C) = AB+AC$$
5. $$(A+B)C = AC+BC$$
6. $$(\alpha\beta)A = \alpha(\beta A)$$
7. $$\alpha( AB )= (\alpha A)B = A(\alpha B)$$
8. $$(\alpha + \beta)A = \alpha A + \beta B$$
9. $$\alpha(A + B) = \alpha A + \alpha B$$

### Rules for transpose:

1. $$(A^T)^T = A$$
2. $$(\alpha A)^T = \alpha (A^T)$$
3. $$(A \pm B)^T = A^T \pm B^T$$
4. $$(AB)^T = B^TA^T$$
5. $$(ABC)^T = C^TB^TA^T\ (etc.)$$

Note in the last two rules, the order of multiplication reverses.

~~Example 4

Remember that $\textbf{A}$ is symmetric if $\textbf{A} = \textbf{A}^T$

Given $\textbf{A}$ and $\textbf{B}$ are symmetric. Are the following symmetric?

1. $\textbf{A} + \textbf{B}$

To check, we need $(\textbf{A} + \textbf{B})^T$.

$$(\textbf{A} + \textbf{B})^T = \textbf{A}^T + \textbf{B}^T = \textbf{A} + \textbf{B}$$

So this is symmetric.

2. $\textbf{A}\textbf{B}$

$$(\textbf{A}\textbf{B})^T = \textbf{B}^T\textbf{A}^T = \textbf{B}\textbf{A}$$

This is not symmetric

~~

### Rules for inverse:

If $A$ and $B$ are non-singular and $AB$ (and $BA$) is non-singular, 

1. $$(AB)^{-1} = B^{-1}A^{-1}$$
2. $$(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$$
3. $$(A^T)^{-1} = (A^{-1})^T$$

~~Example 5

Suppose $\textbf{A}^2 = 0$
Show that $I - A$ and $A - I$ are non-singular and inverses of eachother.

For this to be true,

$$(I -A)(I - A) = I$$
$$I^2 -AI - IA - A^2 = I$$
$$I - A - A = I$$
$$I = I$$

~~

<script src="/source/texme.js"></script>
<link rel="stylesheet" href="/source/theme.css">
