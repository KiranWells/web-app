# Expectation

> Definition:  
> Expectation is the weighted average of all values, which is defined as the sum of all values multiplied by their respective weight, which is their probability.
> $$E[X] = \sum\limits_{x\in X(\Omega)} xP(X = x)$$

The expectation of many repeated experiments is a **repeated expectation**.

## Properties

Expectation is a linear function, so we can expand some equations inside an expectation:

$$E[X_1 + 3X_2 + 2] = E[X_1] + 3E[X_2] + 2$$

If $X$ is a discrete random variable with $g(x)$ as a function, then $Y = g(X)$ defines another discrete random variable. The expectation of $Y$ is given by:

$$E[Y] = \sum\limits_{y\in Y} yp_Y(y)$$

However, this can be done instead as a function of the original expectation:

$$E[Y] = E[g(X)] = \sum\limits_{y\in Y} g(x)p_X(x)$$

This allows us to avoid calculating a new PMF for $Y$.

In addition, we can break apart the definition for variance with the linear property of the expectation (Where $\mu = E[X]$):

$$E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2] = E[X^2] - 2\mu E[X] + \mu^2$$

The variance on the other hand is not linear:

$$Var[aX + b] = a^2 Var[X]$$

If $X$ takes only nonnegative integer values, then the following is true:

$$E[X] = \sum\limits_{k=1}^{\infty}Pr(X\ge k)$$

## Expectations of variable types:

### Bernoulli

For example, the expectation of a Bernoulli variable with probability $q$ is:

$$0 * (q-1) + 1 * (q) = q$$

### Binomial

And a Binomial variable of $n, q$:

$$\sum\limits_{x=0}^n \left( \begin{array}{c}n \\ x\end{array} \right)q^x(1-q)^{n-x}$$

Which will simplify to:

$$np$$

This is true because a Binomial variable is just the sum of many Bernoulli variables. Because $E[X]$ is a linear function, the expectation of a sum is equal to the sum of the expectations:

$$E[X] = \sum\limits_{i=1}^n E[X_i] = n * E[X_i] = np$$

Note that the probability $P(X=x)$ is not necessarily linear, so this does not work with the PMF.

### Geometric

The expectation for geometric series is again a weighted average:

$$E[X] = \sum\limits_{i=1}^{\infty}i(1-p)^{i-1}p$$

Which can be simplified to:

$$\frac{1}{p}$$

This is because of the memoryless property. The probability after one test is done is the same as the probability before doing any tests, so you can create a recursive formula for $E[X]$ which simplifies down to $\frac{1}{p}$.

### Poisson

The expectation of a Poisson variable is:

$$E[X] = \lambda$$

The variance is also $\lambda$.

### Hyper-Geometric and Negative Binomial

Through a somewhat complex simplification process, the expectation of a hyper-geometric variable is:

$$E[X] = \frac{mn}{N}$$

The negative binomial variable follows a similar strategy for binomial, giving:

$$E[X] =\sum\limits_{k=1}^r E[X_k] = \sum\limits_{k=1}^r \frac{1}{p} = \frac{r}{p}$$

## Variance

Variance is the spread of the random variable:

$$E[(X-E[X])^2]$$

This is similar to variance in statistics.

## Examples

~~Example: A Betting Strategy

Consider a game where you bet on a coin toss, and you lose the money you bet if you are wrong, and gain that amount of money if you are right. One strategy is to double your bet each time you lose, to ensure that once you win you are at least net positive by one. With an infinite budget, you can always win with this, but what if you have a limited budget?

Defining X as the amount of money you won, if you lose all $N$ coin tosses, it would be:

$$X = -B_1 - B_2 - ... = -B_1 -2B_1 - 4B_1 ... = -(2^N-1)B_1$$

If you win on the $i$th toss for any $i=1..N$, then $X=B_1$. This is because the doubling cancels out to just the original bet.

<!-- The expectation is then given as (with $p$ beging the likelihood of a win):

$$E[X] = -(2^N-1)B_1p^N + B_1p^{N-x}$$ -->

~~

<script src="/source/texme.js"></script>
<link rel="stylesheet" href="/source/theme.css">
