# Expectation

> Definition:  
> Expectation is the weighted average of all values, which is defined as the sum of all values multiplied by their respective weight, which is their probability.
> $$E[X] = \sum\limits_{x\in X(\Omega)} xP(X = x)$$

The expectation of many repeated experiments is a **repeated expectation**.

## Properties

Expectation is a linear function, so we can expand some equations inside an expectation:

$$E[X_1 + 3X_2 + 2] = E[X_1] + 3E[X_2] + 2$$

If $X$ is a discrete random variable with $g(x)$ as a function, then $Y = g(X)$ defines another discrete random variable. The expectation of $Y$ is given by:

$$E[Y] = \sum\limits_{y\in Y} yp_Y(y)$$

However, this can be done instead as a function of the original expectation:

$$E[Y] = E[g(X)] = \sum\limits_{y\in Y} g(x)p_X(x)$$

This allows us to avoid calculating a new PMF for $Y$.

If $X$ takes only nonnegative integer values, then the following is true:

$$E[X] = \sum\limits_{k=1}^{\infty}Pr(X\ge k)$$

An alternative formula can also be used for expectation:

$$E[X] = \sum\limits_{k=1}^{\infty} Pr(X \ge k)$$

## Expectations of variable types:

### Bernoulli

For example, the expectation of a Bernoulli variable with probability $q$ is:

$$0 * (q-1) + 1 * (q) = q$$

### Binomial

And a Binomial variable of $n, q$:

$$\sum\limits_{x=0}^n \left( \begin{array}{c}n \\ x\end{array} \right)q^x(1-q)^{n-x}$$

Which will simplify to:

$$np$$

This is true because a Binomial variable is just the sum of many Bernoulli variables. Because $E[X]$ is a linear function, the expectation of a sum is equal to the sum of the expectations:

$$E[X] = \sum\limits_{i=1}^n E[X_i] = n * E[X_i] = np$$

Note that the probability $P(X=x)$ is not necessarily linear, so this does not work with the PMF.

### Geometric

The expectation for geometric series is again a weighted average:

$$E[X] = \sum\limits_{i=1}^{\infty}i(1-p)^{i-1}p$$

Which can be simplified to:

$$\frac{1}{p}$$

This is because of the memoryless property. The probability after one test is done is the same as the probability before doing any tests, so you can create a recursive formula for $E[X]$ which simplifies down to $\frac{1}{p}$.

In addition, for a geometric random variable

$$Pr(X \ge k) = \sum\limits_{i=k}^{\infty}(1-p)^{i-1}p$$
$$= p \frac{(1-p)^{k-1}}{1-(1-p)}$$
$$= (1-p)^{k-1}$$

This can be used alternatively to compute the expectation:

$$E[X] = \sum\limits_{k=1}^{\infty} (1-p)^{k-1}$$

### Poisson

The expectation of a Poisson variable is:

$$E[X] = \lambda$$

The variance is also $\lambda$.

### Hyper-Geometric and Negative Binomial

Through a somewhat complex simplification process, the expectation of a hyper-geometric variable is:

$$E[X] = \frac{mn}{N}$$

The negative binomial variable follows a similar strategy for binomial, giving:

$$E[X] =\sum\limits_{k=1}^r E[X_k] = \sum\limits_{k=1}^r \frac{1}{p} = \frac{r}{p}$$

## Variance

Variance is the spread of the random variable. It captures how large of a range a random variable can cover, a type of uncertainty measure. It takes the form of an expectation of expectations:

$$E[(X-E[X])^2]$$

This is similar to variance in statistics, and the standard deviation is defined as the square root of variance.

In addition, we can break apart the definition for variance with the linear property of the expectation (Where $\mu = E[X]$):

$$E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2] = E[X^2] - 2\mu E[X] + \mu^2 = E[X^2] - 2(E[X]) E[X] + (E[X])^2$$

$$Var[X] = E[X^2] - (E[X])^2$$

The variance, in contrast to the expectation, is not linear:

$$Var[aX + b] = a^2 Var[X]$$

### Moment

A $n$th-order moment is defined as:

$$E[X^n]$$

Therefore, the expectation is a first order moment. The variance is a second order moment, but because of the subtraction in the formula it is called a *centered* second order moment. A general $n$th-order centered moment is defined as:

$$E[(X - E[X])^n]$$

### Generating Function

The generating function is defined as:

$$G(z) = E[z^X]$$

This simplifies (using a Taylor expansion), and allows you to find the probability mass function of $X$. With continuous random variables, this is a $z$-transformation.

The moment generating function is defined as:

$$M(s) = E[e^{sX}]$$

This also allows you to determine a moment of $X$ by expanding into a series. With continuous random variables, this is a Laplace transformation.

## Examples

~~Example: A Betting Strategy

Consider a game where you bet on a coin toss, and you lose the money you bet if you are wrong, and gain that amount of money if you are right. One strategy is to double your bet each time you lose, to ensure that once you win you are at least net positive by one. With an infinite budget, you can always win with this, but what if you have a limited budget?

Defining X as the amount of money you won, if you lose all $N$ coin tosses, it would be:

$$X = -B_1 - B_2 - ... = -B_1 -2B_1 - 4B_1 ... = -(2^N-1)B_1$$

If you win on the $i$th toss for any $i=1..N$, then $X=B_1$. This is because the doubling cancels out to just the original bet.

<!-- The expectation is then given as (with $p$ being the likelihood of a win):

$$E[X] = -(2^N-1)B_1p^N + B_1p^{N-x}$$ -->

~~

~~Example: squared dice

Given $X$ as the result of a fair die, what is the expectation of $X^2$?

One way to solve this is to calculate all of the values $X^2$ could be, then find their expectation.

$$X^2 = \{1,4,9,16,25,36\}$$

$$E[X^2] = \sum (x)\frac{1}{6} = \frac{91}{6}$$

The second way would be to use the expectation and variance of $X$ to calculate this value.

This calculation can then be used to calculate the variance of $X$.

~~

~~Example: picking without replacement

An urn contains 4 white and 8 black balls. Balls are randomly selected without replacement for 4 times, one at a time, what is the expected number of white balls?

This is a hyper-geometric random variable, but can be modeled by a random variable for each draw. If $E[X_i]$ is the expectation of draw $i$:

$$E[X] = \sum\limits_{i=1}^4 E[X_i] = \frac{4}{3}$$

The probability of draw $i$ can be calculated by splitting later probabilities into the probability given the first succeeded and the first did not succeed (total probability theorem). This turns out to always be the same as the probability of the first one.

~~

<script src="/source/texme.js"></script>
<link rel="stylesheet" href="/source/theme.css">
